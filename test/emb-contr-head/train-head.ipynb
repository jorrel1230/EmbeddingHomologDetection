{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import faiss\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetching Data from Storages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_batched_arr(arr_type, n=8):\n",
    "    arrays = [np.load(f'/scratch/gpfs/jr8867/embeddings/scop/batch-{i}-{arr_type}.npy') for i in range(n)]\n",
    "    return np.concatenate(arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35977, 1280)\n",
      "(35977,)\n"
     ]
    }
   ],
   "source": [
    "embeddings = fetch_batched_arr('embeddings')\n",
    "indices = fetch_batched_arr('indices')\n",
    "print(embeddings.shape)\n",
    "print(indices.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved embeddings and indices to /scratch/gpfs/jr8867/embeddings/scop\n"
     ]
    }
   ],
   "source": [
    "# Create directory if it doesn't exist\n",
    "save_dir = '/scratch/gpfs/jr8867/embeddings/scop'\n",
    "\n",
    "# Save the arrays\n",
    "np.save(os.path.join(save_dir, 'embeddings.npy'), embeddings)\n",
    "np.save(os.path.join(save_dir, 'indices.npy'), indices)\n",
    "\n",
    "print(f\"Saved embeddings and indices to {save_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File size of embeddings.npy: 175.67 MB\n"
     ]
    }
   ],
   "source": [
    "embeddings_file_path = os.path.join(save_dir, 'embeddings.npy')\n",
    "embeddings_file_size = os.path.getsize(embeddings_file_path)\n",
    "embeddings_file_size_mb = embeddings_file_size / (1024 * 1024)\n",
    "print(f\"File size of embeddings.npy: {embeddings_file_size_mb:.2f} MB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>uid</th>\n",
       "      <th>fa</th>\n",
       "      <th>sf</th>\n",
       "      <th>seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Q03131</td>\n",
       "      <td>4000119</td>\n",
       "      <td>3000038</td>\n",
       "      <td>MSGPRSRTTSRRTPVRIGAVVVASSTSELLDGLAAVADGRPHASVV...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>P09147</td>\n",
       "      <td>4000088</td>\n",
       "      <td>3000038</td>\n",
       "      <td>MRVLVTGGSGYIGSHTCVQLLQNGHDVIILDNLCNSKRSVLPVIER...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>P61889</td>\n",
       "      <td>4000045</td>\n",
       "      <td>3000039</td>\n",
       "      <td>MKVAVLGAAGGIGQALALLLKTQLPSGSELSLYDIAPVTPGVAVDL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>P00334</td>\n",
       "      <td>4000029</td>\n",
       "      <td>3000038</td>\n",
       "      <td>MSFTLTNKNVIFVAGLGGIGLDTSKELLKRDLKNLVILDRIENPAA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>O33830</td>\n",
       "      <td>4000089</td>\n",
       "      <td>3000039</td>\n",
       "      <td>MPSVKIGIIGAGSAVFSLRLVSDLCKTPGLSGSTVTLMDIDEERLD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35972</th>\n",
       "      <td>35972</td>\n",
       "      <td>P20585</td>\n",
       "      <td>4004015</td>\n",
       "      <td>3000587</td>\n",
       "      <td>MSRRKPASGGLAASSSAPARQAVLSRFFQSTGSLKSTSSSTGAADQ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35973</th>\n",
       "      <td>35973</td>\n",
       "      <td>P20585</td>\n",
       "      <td>4004015</td>\n",
       "      <td>3002020</td>\n",
       "      <td>MSRRKPASGGLAASSSAPARQAVLSRFFQSTGSLKSTSSSTGAADQ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35974</th>\n",
       "      <td>35974</td>\n",
       "      <td>P52701</td>\n",
       "      <td>4004015</td>\n",
       "      <td>3001688</td>\n",
       "      <td>MSRQSTLYSFFPKSPALSDANKASARASREGGRAAAAPGASPSPGG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35975</th>\n",
       "      <td>35975</td>\n",
       "      <td>P52701</td>\n",
       "      <td>4004015</td>\n",
       "      <td>3000587</td>\n",
       "      <td>MSRQSTLYSFFPKSPALSDANKASARASREGGRAAAAPGASPSPGG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35976</th>\n",
       "      <td>35976</td>\n",
       "      <td>P52701</td>\n",
       "      <td>4004015</td>\n",
       "      <td>3002020</td>\n",
       "      <td>MSRQSTLYSFFPKSPALSDANKASARASREGGRAAAAPGASPSPGG...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35977 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index     uid       fa       sf  \\\n",
       "0          0  Q03131  4000119  3000038   \n",
       "1          1  P09147  4000088  3000038   \n",
       "2          2  P61889  4000045  3000039   \n",
       "3          3  P00334  4000029  3000038   \n",
       "4          4  O33830  4000089  3000039   \n",
       "...      ...     ...      ...      ...   \n",
       "35972  35972  P20585  4004015  3000587   \n",
       "35973  35973  P20585  4004015  3002020   \n",
       "35974  35974  P52701  4004015  3001688   \n",
       "35975  35975  P52701  4004015  3000587   \n",
       "35976  35976  P52701  4004015  3002020   \n",
       "\n",
       "                                                     seq  \n",
       "0      MSGPRSRTTSRRTPVRIGAVVVASSTSELLDGLAAVADGRPHASVV...  \n",
       "1      MRVLVTGGSGYIGSHTCVQLLQNGHDVIILDNLCNSKRSVLPVIER...  \n",
       "2      MKVAVLGAAGGIGQALALLLKTQLPSGSELSLYDIAPVTPGVAVDL...  \n",
       "3      MSFTLTNKNVIFVAGLGGIGLDTSKELLKRDLKNLVILDRIENPAA...  \n",
       "4      MPSVKIGIIGAGSAVFSLRLVSDLCKTPGLSGSTVTLMDIDEERLD...  \n",
       "...                                                  ...  \n",
       "35972  MSRRKPASGGLAASSSAPARQAVLSRFFQSTGSLKSTSSSTGAADQ...  \n",
       "35973  MSRRKPASGGLAASSSAPARQAVLSRFFQSTGSLKSTSSSTGAADQ...  \n",
       "35974  MSRQSTLYSFFPKSPALSDANKASARASREGGRAAAAPGASPSPGG...  \n",
       "35975  MSRQSTLYSFFPKSPALSDANKASARASREGGRAAAAPGASPSPGG...  \n",
       "35976  MSRQSTLYSFFPKSPALSDANKASARASREGGRAAAAPGASPSPGG...  \n",
       "\n",
       "[35977 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_df = pd.read_csv('/scratch/gpfs/jr8867/datasets/scop/scop_data.csv')\n",
    "metadata_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of the variable: 184202368 bytes\n",
      "Memory usage of the variable in MB: 175.67 MB\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "# Check memory usage of a variable\n",
    "variable_memory = sys.getsizeof(embeddings)  # Replace 'embeddings' with the variable you want to check\n",
    "print(f'Memory usage of the variable: {variable_memory} bytes')\n",
    "# Convert bytes to megabytes\n",
    "variable_memory_mb = variable_memory / (1024 * 1024)\n",
    "print(f'Memory usage of the variable in MB: {variable_memory_mb:.2f} MB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All arrays in embeddings have a magnitude of 1.\n"
     ]
    }
   ],
   "source": [
    "if np.all(np.isclose(np.linalg.norm(embeddings, axis=1), 1)):\n",
    "    print(\"All arrays in embeddings have a magnitude of 1.\")\n",
    "else:\n",
    "    print(\"Some arrays in embeddings do not have a magnitude of 1.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grabbing Super-family information from scop dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "superfamilies = np.array([metadata_df.loc[metadata_df['index'] == i, 'sf'].values[0] for i in indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  25   25   26 ... 1645  556 1968]\n"
     ]
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "labels = label_encoder.fit_transform(superfamilies)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count how many samples each label has\n",
    "unique, counts = np.unique(labels, return_counts=True)\n",
    "\n",
    "# Keep only labels that have at least 2 samples\n",
    "valid_labels = unique[counts > 1]\n",
    "\n",
    "# Create a boolean mask for those labels\n",
    "mask = np.isin(labels, valid_labels)\n",
    "\n",
    "# Filter embeddings and labels\n",
    "embeddings = embeddings[mask]\n",
    "labels = labels[mask]\n",
    "\n",
    "# Now do the stratified split\n",
    "train_embeddings, test_embeddings, train_labels, test_labels = train_test_split(\n",
    "    embeddings, labels, test_size=0.2, random_state=42, stratify=labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProteinDataset(Dataset):\n",
    "    def __init__(self, embeddings, labels):\n",
    "        self.embeddings = torch.tensor(embeddings, dtype=torch.float32)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.embeddings)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.embeddings[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Triplet Loss Sampling Function for Contrasted Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Triplet Sampling Function\n",
    "def get_triplets(embeddings, labels, num_triplets=10000):\n",
    "    triplets = []\n",
    "    label_dict = {}\n",
    "    \n",
    "    for i, label in enumerate(labels):\n",
    "        if label not in label_dict:\n",
    "            label_dict[label] = []\n",
    "        label_dict[label].append(i)\n",
    "    \n",
    "    for _ in range(num_triplets):\n",
    "        anchor_idx = np.random.randint(0, len(labels))\n",
    "        anchor_label = labels[anchor_idx]\n",
    "        \n",
    "        positive_idx = np.random.choice(label_dict[anchor_label])\n",
    "        \n",
    "        negative_label = np.random.choice([l for l in label_dict.keys() if l != anchor_label])\n",
    "        negative_idx = np.random.choice(label_dict[negative_label])\n",
    "        \n",
    "        triplets.append((anchor_idx, positive_idx, negative_idx))\n",
    "    \n",
    "    return triplets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projection Head Model\n",
    "\n",
    "This is a simple feedforward net. The goal with this projection head is just to provide some non-linear transformation to project the initial embeddings into a new vector space with superfamilies spread apart. We can also lower the dimensionality while we're at it, knocking 2 birds with 1 stone and reducing compute costs this way as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define MLP Projection Head\n",
    "class ProjectionHead(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim=128, normalize_output=True):\n",
    "        super(ProjectionHead, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, output_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.normalize_output = normalize_output\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        # Optionally normalize final embeddings\n",
    "        if self.normalize_output:\n",
    "            x = torch.nn.functional.normalize(x, p=2, dim=-1)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Loop\n",
    "\n",
    "def train_projection_head(train_embeddings, train_labels, test_embeddings, test_labels, epochs=10, batch_size=256, lr=0.001):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = ProjectionHead(input_dim=train_embeddings.shape[1], output_dim=128, normalize_output=True).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.TripletMarginLoss(margin=0.2)\n",
    "\n",
    "    train_dataset = ProteinDataset(train_embeddings, train_labels)\n",
    "    test_dataset = ProteinDataset(test_embeddings, test_labels)\n",
    "\n",
    "    train_triplets = get_triplets(train_embeddings, train_labels, num_triplets=200000)\n",
    "    test_triplets = get_triplets(test_embeddings, test_labels, num_triplets=10000)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for anchor_idx, pos_idx, neg_idx in tqdm(train_triplets, desc=f\"Epoch {epoch+1} [Train]\"):\n",
    "            anchor = train_dataset[anchor_idx][0].to(device)\n",
    "            positive = train_dataset[pos_idx][0].to(device)\n",
    "            negative = train_dataset[neg_idx][0].to(device)\n",
    "\n",
    "            anchor_out = model(anchor)\n",
    "            positive_out = model(positive)\n",
    "            negative_out = model(negative)\n",
    "\n",
    "            loss = criterion(anchor_out, positive_out, negative_out)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        avg_train_loss = total_loss / len(train_triplets)\n",
    "\n",
    "        # Evaluation on test set\n",
    "        model.eval()\n",
    "        total_test_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for anchor_idx, pos_idx, neg_idx in tqdm(test_triplets, desc=f\"Epoch {epoch+1} [Test]\"):\n",
    "                anchor = test_dataset[anchor_idx][0].to(device)\n",
    "                positive = test_dataset[pos_idx][0].to(device)\n",
    "                negative = test_dataset[neg_idx][0].to(device)\n",
    "\n",
    "                anchor_out = model(anchor)\n",
    "                positive_out = model(positive)\n",
    "                negative_out = model(negative)\n",
    "\n",
    "                t_loss = criterion(anchor_out, positive_out, negative_out)\n",
    "                total_test_loss += t_loss.item()\n",
    "        avg_test_loss = total_test_loss / len(test_triplets)\n",
    "\n",
    "        print(f\"Epoch {epoch+1} - Train Loss: {avg_train_loss:.4f} | Test Loss: {avg_test_loss:.4f}\")\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 [Train]:  12%|███████████▉                                                                                       | 3390/28105 [00:06<00:48, 505.44it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m projection_model \u001b[38;5;241m=\u001b[39m train_projection_head(train_embeddings, train_labels,\n\u001b[1;32m      3\u001b[0m                                          test_embeddings, test_labels,\n\u001b[1;32m      4\u001b[0m                                          epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m, lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n",
      "Cell \u001b[0;32mIn[18], line 29\u001b[0m, in \u001b[0;36mtrain_projection_head\u001b[0;34m(train_embeddings, train_labels, test_embeddings, test_labels, epochs, batch_size, lr)\u001b[0m\n\u001b[1;32m     27\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(anchor_out, positive_out, negative_out)\n\u001b[1;32m     28\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 29\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     30\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     31\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/.conda/envs/plm/lib/python3.12/site-packages/torch/_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    580\u001b[0m     )\n\u001b[0;32m--> 581\u001b[0m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mbackward(\n\u001b[1;32m    582\u001b[0m     \u001b[38;5;28mself\u001b[39m, gradient, retain_graph, create_graph, inputs\u001b[38;5;241m=\u001b[39minputs\n\u001b[1;32m    583\u001b[0m )\n",
      "File \u001b[0;32m~/.conda/envs/plm/lib/python3.12/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m _engine_run_backward(\n\u001b[1;32m    348\u001b[0m     tensors,\n\u001b[1;32m    349\u001b[0m     grad_tensors_,\n\u001b[1;32m    350\u001b[0m     retain_graph,\n\u001b[1;32m    351\u001b[0m     create_graph,\n\u001b[1;32m    352\u001b[0m     inputs,\n\u001b[1;32m    353\u001b[0m     allow_unreachable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    354\u001b[0m     accumulate_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    355\u001b[0m )\n",
      "File \u001b[0;32m~/.conda/envs/plm/lib/python3.12/site-packages/torch/autograd/graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    826\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    827\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "projection_model = train_projection_head(train_embeddings, train_labels,\n",
    "                                         test_embeddings, test_labels,\n",
    "                                         epochs=5, batch_size=256, lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(projection_model.state_dict(), \"/scratch/gpfs/jr8867/models/projection_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save new embeddings\n",
    "with torch.no_grad():\n",
    "    refined_embeddings = projection_model(torch.tensor(embeddings, dtype=torch.float32).to(\"cuda\")).cpu().numpy()\n",
    "\n",
    "np.save(\"refined_embeddings.npy\", refined_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FAISS Indexing\n",
    "index = faiss.IndexFlatL2(refined_embeddings.shape[1])\n",
    "index.add(refined_embeddings)\n",
    "faiss.write_index(index, \"faiss_index_refined.idx\")\n",
    "\n",
    "print(\"Saved refined embeddings and FAISS index!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
